# Docker Compose for AutoBot Hybrid Deployment
# Local orchestrator + containerized AI stack

name: autobot

services:
  # Redis Stack (with search, JSON, and vector capabilities)
  autobot-redis:
    image: redis/redis-stack:7.4.0-v1
    container_name: autobot-redis
    restart: unless-stopped
    ports:
      - "${AUTOBOT_REDIS_PORT:-6379}:6379"
      - "${AUTOBOT_REDIS_INSIGHT_PORT:-8002}:8002"  # RedisInsight web UI
    volumes:
      - autobot_redis_data:/data
    environment:
      - REDIS_ARGS=--appendonly yes --save 60 1
      - REDISINSIGHT_PORT=8002  # Configure RedisInsight to use port 8002
    networks:
      - autobot-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # AI Stack Container (LangChain + LlamaIndex)
  autobot-ai-stack:
    build:
      context: .
      dockerfile: docker/ai-stack/Dockerfile
    container_name: autobot-ai-stack
    restart: unless-stopped
    ports:
      - "${AUTOBOT_AI_STACK_PORT:-8080}:8080"  # AI API port
    volumes:
      # Centralized data volumes
      - ../volumes/prompts:/app/prompts:ro
      - ../volumes/knowledge_base:/app/knowledge_base:ro
      - ../volumes/models:/app/models
      - ../volumes/config:/app/config:ro
      # Container-specific volumes
      - autobot_ai_data:/app/data
      - autobot_ai_logs:/app/logs
      - ../../src:/app/src:ro  # Read-only source code mount for development
    environment:
      - AI_SERVER_HOST=0.0.0.0
      - AI_SERVER_PORT=8080
      - AI_SERVER_WORKERS=1
      - OLLAMA_HOST=${AUTOBOT_OLLAMA_HOST:-127.0.0.2}:${AUTOBOT_OLLAMA_PORT:-11434}
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=${AUTOBOT_REDIS_PORT:-6379}
      - CHROMA_DB_PATH=/app/data/chroma_db
      - DISABLE_EXTERNAL_APIS=true
      - PYTHONPATH=/app:/app/src
    depends_on:
      autobot-redis:
        condition: service_healthy
    networks:
      - autobot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # NPU Worker (Intel NPU + NVIDIA GPU Accelerated Inference)
  autobot-npu-worker:
    build:
      context: ../..
      dockerfile: docker/npu-worker/Dockerfile.npu-worker-simple-worker
    container_name: autobot-npu-worker
    restart: unless-stopped
    ports:
      - "${AUTOBOT_NPU_WORKER_PORT:-8081}:8081"  # NPU API port
    volumes:
      # Centralized data volumes
      - ../volumes/prompts:/app/prompts:ro
      - ../volumes/knowledge_base:/app/knowledge_base:ro
      - ../volumes/models:/app/models
      - ../volumes/config:/app/config:ro
      # Container-specific volumes
      - autobot_npu_logs:/app/logs
      - ../../src:/app/src:ro  # Read-only source code mount
      # Mount NPU devices and firmware (if available)
      - /dev:/dev:ro
      - /lib/firmware:/lib/firmware:ro
      # Mount NPU driver libraries from host
      - /usr/local/lib:/usr/local/lib:ro
    environment:
      - NPU_WORKER_HOST=0.0.0.0
      - NPU_WORKER_PORT=8081
      - NPU_WORKER_WORKERS=1
      - OPENVINO_DEVICE=AUTO  # Auto-detect best device (NPU > GPU > CPU)
      - OV_LOG_LEVEL=ERROR
      - NPU_LOG_LEVEL=INFO
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=${AUTOBOT_REDIS_PORT:-6379}
      - PYTHONPATH=/app:/app/src
      # Python shared library path fix
      - LD_LIBRARY_PATH=/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib/python3.10
      # NVIDIA GPU support
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    depends_on:
      autobot-redis:
        condition: service_healthy
    networks:
      - autobot-network
    # NPU requires privileged access for hardware
    privileged: true
    # GPU runtime support for NVIDIA cards
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Seq Log Viewer (Centralized Logging)
  autobot-seq:
    image: datalust/seq:latest
    container_name: autobot-seq
    restart: unless-stopped
    ports:
      - "${AUTOBOT_LOG_VIEWER_PORT:-5341}:80"
    volumes:
      - autobot_seq_data:/data
    environment:
      - ACCEPT_EULA=Y
      - SEQ_FIRSTRUN_ADMINUSERNAME=admin
      - SEQ_FIRSTRUN_ADMINPASSWORD=${AUTOBOT_SEQ_ADMIN_PASSWORD}
    networks:
      - autobot-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    labels:
      - "autobot.service=seq"
      - "autobot.logging=centralized"

networks:
  autobot-network:
    external: true
    name: autobot-network

volumes:
  autobot_redis_data:
    name: autobot_redis_data
  autobot_ai_data:
    name: autobot_ai_data
  autobot_ai_models:
    name: autobot_ai_models
  autobot_ai_logs:
    name: autobot_ai_logs
  autobot_npu_models:
    name: autobot_npu_models
  autobot_npu_logs:
    name: autobot_npu_logs
  autobot_seq_data:
    name: autobot_seq_data
