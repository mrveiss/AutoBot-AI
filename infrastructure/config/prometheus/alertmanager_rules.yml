# Prometheus AlertManager Rules for AutoBot
# Phase 3: Alert Migration (Issue #346)
# Copyright (c) 2025 mrveiss
# Author: mrveiss

groups:
  # System Resource Alerts
  - name: autobot_system_resources
    rules:
      # CPU Alerts
      - alert: HighCPUUsage
        expr: autobot_cpu_usage_percent > 80
        for: 5m
        labels:
          severity: high
          component: system
          resource: cpu
        annotations:
          summary: "VM0 High CPU Usage"
          description: "CPU usage is {{ $value }}% (threshold: 80%)"
          recommendation: "Check for runaway processes or high load"

      - alert: CriticalCPUUsage
        expr: autobot_cpu_usage_percent > 95
        for: 2m
        labels:
          severity: critical
          component: system
          resource: cpu
        annotations:
          summary: "VM0 Critical CPU Usage"
          description: "CPU usage is {{ $value }}% (threshold: 95%)"
          recommendation: "Immediate action required - system may become unresponsive"

      # Memory Alerts
      - alert: HighMemoryUsage
        expr: autobot_memory_usage_percent > 85
        for: 10m
        labels:
          severity: high
          component: system
          resource: memory
        annotations:
          summary: "VM0 High Memory Usage"
          description: "Memory usage is {{ $value }}% (threshold: 85%)"
          recommendation: "Check for memory leaks or high memory consumers"

      - alert: CriticalMemoryUsage
        expr: autobot_memory_usage_percent > 95
        for: 3m
        labels:
          severity: critical
          component: system
          resource: memory
        annotations:
          summary: "VM0 Critical Memory Usage"
          description: "Memory usage is {{ $value }}% (threshold: 95%)"
          recommendation: "Immediate action required - OOM killer may activate"

      # Disk Alerts
      - alert: HighDiskUsage
        expr: autobot_disk_usage_percent{mount_point="/"} > 85
        for: 1h
        labels:
          severity: medium
          component: system
          resource: disk
        annotations:
          summary: "VM0 High Disk Usage"
          description: "Disk usage on {{ $labels.mount_point }} is {{ $value }}% (threshold: 85%)"
          recommendation: "Clean up old logs or temporary files"

      - alert: CriticalDiskUsage
        expr: autobot_disk_usage_percent{mount_point="/"} > 95
        for: 15m
        labels:
          severity: critical
          component: system
          resource: disk
        annotations:
          summary: "VM0 Critical Disk Usage"
          description: "Disk usage on {{ $labels.mount_point }} is {{ $value }}% (threshold: 95%)"
          recommendation: "Immediate cleanup required - system may fail to write"

  # Service Health Alerts
  - name: autobot_service_health
    rules:
      - alert: BackendAPIDown
        expr: autobot_service_status{service_name="backend",status="offline"} == 1
        for: 1m
        labels:
          severity: critical
          component: service
          service: backend
        annotations:
          summary: "Backend API Unavailable"
          description: "Backend API is not responding"
          recommendation: "Check backend service logs and restart if necessary"

      - alert: RedisUnavailable
        expr: autobot_service_status{service_name="redis",status="offline"} == 1
        for: 1m
        labels:
          severity: critical
          component: service
          service: redis
        annotations:
          summary: "Redis Database Unavailable"
          description: "Redis database is not accessible"
          recommendation: "Check Redis service on VM3 (172.16.168.23)"

      - alert: OllamaDown
        expr: autobot_service_status{service_name="ollama",status="offline"} == 1
        for: 2m
        labels:
          severity: high
          component: service
          service: ollama
        annotations:
          summary: "Ollama LLM Service Down"
          description: "Ollama LLM service is not responding"
          recommendation: "Check AI Stack VM4 (172.16.168.24)"

      - alert: ServiceHighResponseTime
        expr: autobot_service_response_time_seconds > 5.0
        for: 5m
        labels:
          severity: medium
          component: service
          resource: performance
        annotations:
          summary: "Service High Response Time"
          description: "{{ $labels.service_name }} response time is {{ $value }}s (threshold: 5s)"
          recommendation: "Check service performance and resource usage"

      - alert: ServiceLowHealthScore
        expr: autobot_service_health_score < 50
        for: 5m
        labels:
          severity: high
          component: service
          resource: health
        annotations:
          summary: "Service Low Health Score"
          description: "{{ $labels.service_name }} health score is {{ $value }}/100 (threshold: 50)"
          recommendation: "Investigate service health issues"

  # Error Rate Alerts
  - name: autobot_error_monitoring
    rules:
      - alert: HighErrorRate
        expr: rate(autobot_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: high
          component: errors
        annotations:
          summary: "High Error Rate Detected"
          description: "Error rate is {{ $value }} errors/5min (threshold: 10)"
          recommendation: "Check error logs for patterns"

      - alert: CriticalErrorSpike
        expr: rate(autobot_errors_total[1m]) > 50
        for: 1m
        labels:
          severity: critical
          component: errors
        annotations:
          summary: "Critical Error Spike"
          description: "Error spike detected: {{ $value }} errors/min (threshold: 50)"
          recommendation: "Immediate investigation required"

      - alert: ComponentErrorRate
        expr: autobot_error_rate{time_window="1m"} > 0.1
        for: 5m
        labels:
          severity: medium
          component: errors
        annotations:
          summary: "Component Error Rate Elevated"
          description: "{{ $labels.component }} error rate is {{ $value }} errors/min"
          recommendation: "Check component-specific logs"

  # Claude API Alerts
  - name: autobot_claude_api
    rules:
      - alert: ClaudeAPIHighFailureRate
        expr: rate(autobot_claude_api_requests_total{success="false"}[5m]) / rate(autobot_claude_api_requests_total[5m]) > 0.1
        for: 5m
        labels:
          severity: high
          component: claude_api
        annotations:
          summary: "Claude API High Failure Rate"
          description: "Claude API failure rate is {{ $value | humanizePercentage }}"
          recommendation: "Check API connectivity and rate limits"

      - alert: ClaudeAPISlowResponses
        expr: histogram_quantile(0.95, rate(autobot_claude_api_response_time_seconds_bucket[5m])) > 10
        for: 5m
        labels:
          severity: medium
          component: claude_api
        annotations:
          summary: "Claude API Slow Responses"
          description: "95th percentile response time is {{ $value }}s (threshold: 10s)"
          recommendation: "Check network latency and API status"

      - alert: ClaudeAPIRateLimitLow
        expr: autobot_claude_api_rate_limit_remaining < 100
        for: 1m
        labels:
          severity: warning
          component: claude_api
        annotations:
          summary: "Claude API Rate Limit Low"
          description: "Only {{ $value }} requests remaining"
          recommendation: "Slow down API requests to avoid rate limiting"

  # Workflow Alerts
  - name: autobot_workflow_monitoring
    rules:
      - alert: WorkflowHighFailureRate
        expr: rate(autobot_workflow_executions_total{status="failed"}[10m]) / rate(autobot_workflow_executions_total[10m]) > 0.2
        for: 10m
        labels:
          severity: high
          component: workflow
        annotations:
          summary: "Workflow High Failure Rate"
          description: "Workflow failure rate is {{ $value | humanizePercentage }} (threshold: 20%)"
          recommendation: "Check workflow execution logs"

      - alert: WorkflowLongDuration
        expr: histogram_quantile(0.95, rate(autobot_workflow_duration_seconds_bucket[10m])) > 600
        for: 10m
        labels:
          severity: medium
          component: workflow
        annotations:
          summary: "Workflow Long Duration"
          description: "95th percentile workflow duration is {{ $value }}s (threshold: 600s)"
          recommendation: "Optimize workflow execution or check for blocking operations"

  # Network Alerts
  - name: autobot_network_monitoring
    rules:
      - alert: HighNetworkTraffic
        expr: rate(autobot_network_bytes_total[5m]) > 100000000  # 100 MB/s
        for: 5m
        labels:
          severity: medium
          component: network
        annotations:
          summary: "High Network Traffic"
          description: "Network traffic is {{ $value | humanize }}B/s (threshold: 100MB/s)"
          recommendation: "Check for unusual network activity"

  # Circuit Breaker Alerts (Issue #69)
  - name: autobot_circuit_breaker
    rules:
      # Circuit breaker opened - critical for any service
      - alert: CircuitBreakerOpen
        expr: autobot_circuit_breaker_state == 1
        for: 30s
        labels:
          severity: critical
          component: circuit_breaker
        annotations:
          summary: "Circuit Breaker OPEN: {{ $labels.database }}"
          description: "Circuit breaker for {{ $labels.database }} has opened with {{ $value }} failures"
          recommendation: "Check {{ $labels.database }} service health, logs, and connectivity"

      # Circuit breaker in half-open state - service recovering
      - alert: CircuitBreakerHalfOpen
        expr: autobot_circuit_breaker_state == 2
        for: 2m
        labels:
          severity: warning
          component: circuit_breaker
        annotations:
          summary: "Circuit Breaker HALF-OPEN: {{ $labels.database }}"
          description: "Circuit breaker for {{ $labels.database }} is testing recovery"
          recommendation: "Monitor service stability during recovery period"

      # High failure count approaching threshold
      - alert: CircuitBreakerHighFailures
        expr: autobot_circuit_breaker_failure_count >= 3
        for: 1m
        labels:
          severity: warning
          component: circuit_breaker
        annotations:
          summary: "Circuit Breaker High Failures: {{ $labels.database }}"
          description: "{{ $labels.database }} has {{ $value }} failures (threshold: 5)"
          recommendation: "Investigate service issues before circuit opens"

      # Circuit breaker event spike (multiple opens in short time)
      - alert: CircuitBreakerEventSpike
        expr: rate(autobot_circuit_breaker_events_total{event="opened"}[5m]) > 0.1
        for: 2m
        labels:
          severity: high
          component: circuit_breaker
        annotations:
          summary: "Circuit Breaker Event Spike: {{ $labels.database }}"
          description: "Multiple circuit breaker openings detected for {{ $labels.database }}"
          recommendation: "Service is unstable - investigate root cause"

  # Redis-Specific Alerts (Issue #69)
  - name: autobot_redis_alerts
    rules:
      # Redis server unavailable
      - alert: RedisServerDown
        expr: autobot_redis_server_available == 0
        for: 30s
        labels:
          severity: critical
          component: redis
          service: redis
        annotations:
          summary: "Redis Server Down: {{ $labels.database }}"
          description: "Redis server {{ $labels.database }} is unavailable"
          recommendation: "Check Redis service on VM3 (172.16.168.23:6379)"

      # Redis connection errors
      - alert: RedisConnectionErrors
        expr: rate(autobot_redis_connection_errors_total[5m]) > 1
        for: 2m
        labels:
          severity: high
          component: redis
        annotations:
          summary: "Redis Connection Errors: {{ $labels.database }}"
          description: "{{ $value }} connection errors/min for {{ $labels.database }} ({{ $labels.error_type }})"
          recommendation: "Check network connectivity and Redis configuration"

      # Redis high memory usage
      - alert: RedisHighMemory
        expr: autobot_redis_memory_used_bytes / autobot_redis_memory_peak_bytes > 0.9
        for: 10m
        labels:
          severity: warning
          component: redis
        annotations:
          summary: "Redis High Memory: {{ $labels.database }}"
          description: "Redis {{ $labels.database }} memory usage at {{ $value | humanizePercentage }}"
          recommendation: "Consider memory cleanup or increase maxmemory"

      # Redis connection pool exhaustion
      - alert: RedisPoolExhausted
        expr: autobot_redis_connections_available / autobot_redis_connections_max < 0.1
        for: 1m
        labels:
          severity: high
          component: redis
        annotations:
          summary: "Redis Pool Exhausted: {{ $labels.database }}"
          description: "Only {{ $value | humanizePercentage }} connections available in {{ $labels.database }} pool"
          recommendation: "Increase pool size or check for connection leaks"

      # Redis operation latency
      - alert: RedisHighLatency
        expr: histogram_quantile(0.95, rate(autobot_redis_operation_latency_seconds_bucket[5m])) > 0.1
        for: 5m
        labels:
          severity: medium
          component: redis
        annotations:
          summary: "Redis High Latency: {{ $labels.database }}"
          description: "95th percentile latency for {{ $labels.database }} is {{ $value }}s"
          recommendation: "Check Redis server load and network latency"

  # NPU Worker Alerts (Issue #69)
  - name: autobot_npu_alerts
    rules:
      # NPU worker circuit breaker open
      - alert: NPUCircuitBreakerOpen
        expr: autobot_circuit_breaker_state{database=~"npu.*"} == 1
        for: 30s
        labels:
          severity: critical
          component: npu
          service: npu_worker
        annotations:
          summary: "NPU Circuit Breaker OPEN"
          description: "NPU worker circuit breaker opened - hardware acceleration unavailable"
          recommendation: "Check NPU Worker VM2 (172.16.168.22:8081) and OpenVINO status"

      # NPU worker high failure rate
      - alert: NPUHighFailureRate
        expr: rate(autobot_circuit_breaker_events_total{database=~"npu.*",event="failure"}[5m]) > 0.5
        for: 3m
        labels:
          severity: high
          component: npu
        annotations:
          summary: "NPU Worker High Failure Rate"
          description: "NPU worker experiencing {{ $value }} failures/min"
          recommendation: "Check NPU worker logs and hardware status"

  # Resource Exhaustion Alerts (Issue #69)
  - name: autobot_resource_exhaustion
    rules:
      # Connection exhaustion across services
      - alert: ConnectionExhaustion
        expr: autobot_redis_connections_active / autobot_redis_connections_max > 0.9
        for: 5m
        labels:
          severity: warning
          component: connections
        annotations:
          summary: "Connection Pool Near Exhaustion: {{ $labels.database }}"
          description: "{{ $value | humanizePercentage }} of connections in use for {{ $labels.database }}"
          recommendation: "Scale connection pool or optimize connection usage"

      # Timeout rate too high
      - alert: HighTimeoutRate
        expr: rate(autobot_timeout_total{status="timeout"}[5m]) / rate(autobot_timeout_total[5m]) > 0.1
        for: 5m
        labels:
          severity: high
          component: timeouts
        annotations:
          summary: "High Timeout Rate: {{ $labels.operation_type }}"
          description: "{{ $value | humanizePercentage }} of {{ $labels.operation_type }} operations timing out"
          recommendation: "Check service performance and increase timeouts if needed"

  # Security Alerts (Issue #69)
  - name: autobot_security_alerts
    rules:
      # Security violation detected
      - alert: SecurityViolation
        expr: rate(autobot_errors_total{category="security"}[5m]) > 0
        for: 1m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Security Violation Detected"
          description: "Security errors detected in {{ $labels.component }}: {{ $value }} events"
          recommendation: "Investigate security logs immediately"

      # Unusual error pattern (potential attack)
      - alert: UnusualErrorPattern
        expr: rate(autobot_errors_total[1m]) > 3 * avg_over_time(rate(autobot_errors_total[1m])[1h:5m])
        for: 2m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "Unusual Error Pattern Detected"
          description: "Error rate is {{ $value }}x higher than normal"
          recommendation: "Review error logs for potential security issues"
