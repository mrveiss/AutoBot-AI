#!/usr/bin/env python3
"""
Comprehensive Code Quality Analysis Dashboard
Runs all analyzers and provides unified quality metrics and recommendations
"""

import asyncio
import json
from pathlib import Path

from src.code_quality_dashboard import CodeQualityDashboard


async def run_comprehensive_quality_analysis():
    """Run comprehensive code quality analysis"""

    print("ğŸ¯ Starting comprehensive code quality analysis...")
    print("This will run all available analyzers:")
    print("  â€¢ Code Duplication Analyzer")
    print("  â€¢ Environment Variable Analyzer")
    print("  â€¢ Performance & Memory Leak Analyzer")
    print("  â€¢ Security Vulnerability Analyzer")
    print("  â€¢ API Consistency Analyzer")
    print("  â€¢ Testing Coverage Gap Analyzer")
    print("  â€¢ Architectural Pattern Analyzer")
    print()

    dashboard = CodeQualityDashboard()

    # Generate comprehensive report
    report = await dashboard.generate_comprehensive_report(
        root_path=".", patterns=["src/**/*.py", "backend/**/*.py"], include_trends=True
    )

    print("=== Code Quality Executive Summary ===\n")

    # Executive summary
    summary = await dashboard.generate_executive_summary(report)
    print(summary)

    print("\n=== Detailed Quality Analysis Results ===\n")

    # Overall metrics
    metrics = report["quality_metrics"]
    issues = report["issue_summary"]

    print(f"ğŸ“Š **Overall Quality Assessment:**")
    print(f"   ğŸ¯ Overall Quality Score: {metrics['overall_score']}/100")
    print(f"   ğŸ“‹ Total Issues Found: {issues['total_issues']}")
    print(f"   ğŸš¨ Critical Issues: {issues['critical_issues']}")
    print(f"   âš ï¸  High Priority Issues: {issues['high_priority_issues']}")
    print(f"   ğŸ“ Files Analyzed: {report['files_analyzed']}")
    print(f"   â±ï¸  Analysis Time: {report['analysis_time_seconds']:.2f} seconds")
    print()

    # Category breakdown
    print("ğŸ·ï¸  **Issues by Category:**")
    for category, count in issues["by_category"].items():
        category_name = category.replace("_", " ").title()
        print(f"   â€¢ {category_name}: {count} issues")
    print()

    # Individual analyzer scores
    print("ğŸ” **Individual Analysis Scores:**")
    score_categories = [
        ("Security", metrics["security_score"], "ğŸ›¡ï¸"),
        ("Performance", metrics["performance_score"], "âš¡"),
        ("Architecture", metrics["architecture_score"], "ğŸ—ï¸"),
        ("Test Coverage", metrics["test_coverage_score"], "ğŸ§ª"),
        ("API Consistency", metrics["api_consistency_score"], "ğŸ”—"),
        ("Code Duplication", metrics["code_duplication_score"], "â™»ï¸"),
        ("Environment Config", metrics["environment_config_score"], "âš™ï¸"),
    ]

    for name, score, emoji in score_categories:
        status = get_score_status(score)
        status_color = get_status_emoji(score)
        print(f"   {emoji} {name}: {score}/100 {status_color} {status}")
    print()

    # Technical debt analysis
    debt = report["technical_debt"]
    print("ğŸ’¸ **Technical Debt Analysis:**")
    print(
        f"   ğŸ“Š Total Estimated Effort: {debt['estimated_total_effort_days']} days ({debt['estimated_total_effort_hours']} hours)"
    )
    print(
        f"   ğŸš¨ Critical Issues Effort: {debt['estimated_critical_effort_hours']} hours"
    )
    print(f"   ğŸ“ˆ Debt Ratio: {debt['debt_ratio']}% of total project")
    print()

    print("ğŸ’° **Effort by Category:**")
    for category, data in debt["effort_by_category"].items():
        category_name = category.replace("_", " ").title()
        print(
            f"   â€¢ {category_name}: {data['count']} issues, {data['effort_hours']} hours"
        )
    print()

    # Top priority issues
    print("ğŸš¨ **Top Priority Issues (Immediate Action Required):**")
    critical_issues = [
        issue
        for issue in report["prioritized_issues"]
        if issue["severity"] == "critical"
    ]
    high_issues = [
        issue for issue in report["prioritized_issues"] if issue["severity"] == "high"
    ]

    top_issues = critical_issues[:5] + high_issues[:5]

    for i, issue in enumerate(top_issues[:10], 1):
        severity_emoji = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}
        emoji = severity_emoji.get(issue["severity"], "âšª")

        print(f"\n{i}. {emoji} **{issue['title']}** ({issue['severity'].upper()})")
        print(f"   ğŸ“‚ Category: {issue['category'].replace('_', ' ').title()}")
        if issue["file_path"] != "Multiple files":
            print(f"   ğŸ“„ File: {issue['file_path']}:{issue['line_number']}")
        print(f"   ğŸ“ Description: {issue['description']}")
        print(f"   ğŸ’¡ Fix: {issue['fix_suggestion']}")
        print(f"   ğŸ”§ Effort: {issue['estimated_effort'].title()}")
        print(f"   ğŸ¯ Priority Score: {issue['priority_score']}/100")

    print()

    # Security-specific analysis
    if report["detailed_analyses"].get("security"):
        security_data = report["detailed_analyses"]["security"]
        if security_data.get("critical_vulnerabilities", 0) > 0:
            print("ğŸ›¡ï¸ **CRITICAL SECURITY ALERT:**")
            print(
                f"   Found {security_data['critical_vulnerabilities']} critical security vulnerabilities!"
            )
            print("   These must be addressed immediately before deployment.")
            print()

    # Performance-specific analysis
    if report["detailed_analyses"].get("performance"):
        perf_data = report["detailed_analyses"]["performance"]
        if perf_data.get("critical_issues", 0) > 0:
            print("âš¡ **CRITICAL PERFORMANCE ALERT:**")
            print(
                f"   Found {perf_data['critical_issues']} critical performance issues!"
            )
            print("   These may cause memory leaks or system instability.")
            print()

    # Testing coverage analysis
    if report["detailed_analyses"].get("testing_coverage"):
        test_data = report["detailed_analyses"]["testing_coverage"]
        coverage = test_data.get("test_coverage_percentage", 0)
        print(f"ğŸ§ª **Testing Coverage Analysis:**")
        print(f"   Current test coverage: {coverage}%")
        if coverage < 70:
            print("   âš ï¸  Coverage is below recommended 70% threshold")
            print("   Consider adding more unit and integration tests")
        print()

    # Improvement recommendations
    print("ğŸ“‹ **Improvement Recommendations (Priority Order):**")
    for i, recommendation in enumerate(report["improvement_recommendations"], 1):
        print(f"{i}. {recommendation}")
    print()

    # Quality trends (if available)
    if report.get("quality_trends"):
        print("ğŸ“ˆ **Quality Trends:**")
        trends = report["quality_trends"]
        if len(trends) > 1:
            latest = trends[0]
            previous = trends[1]
            score_change = latest["overall_score"] - previous["overall_score"]
            trend_emoji = "ğŸ“ˆ" if score_change > 0 else "ğŸ“‰" if score_change < 0 else "â¡ï¸"
            print(f"   {trend_emoji} Score change: {score_change:+.1f} points")

            issue_change = latest["issue_count"] - previous["issue_count"]
            issue_emoji = "ğŸ“‰" if issue_change < 0 else "ğŸ“ˆ" if issue_change > 0 else "â¡ï¸"
            print(f"   {issue_emoji} Issue count change: {issue_change:+d}")
        else:
            print("   ğŸ“Š Baseline measurement established")
        print()

    # Detailed analysis summaries
    print("ğŸ“Š **Detailed Analysis Summaries:**")

    analysis_summaries = {
        "duplication": ("Code Duplication", "â™»ï¸"),
        "environment": ("Environment Variables", "âš™ï¸"),
        "performance": ("Performance", "âš¡"),
        "security": ("Security", "ğŸ›¡ï¸"),
        "api_consistency": ("API Consistency", "ğŸ”—"),
        "testing_coverage": ("Testing Coverage", "ğŸ§ª"),
        "architecture": ("Architecture", "ğŸ—ï¸"),
    }

    for analysis_type, (name, emoji) in analysis_summaries.items():
        data = report["detailed_analyses"].get(analysis_type)
        if data:
            print(f"\n{emoji} **{name} Analysis:**")

            if analysis_type == "duplication":
                groups = data.get("total_duplicate_groups", 0)
                lines_saved = data.get("total_lines_saved", 0)
                print(f"   â€¢ Found {groups} duplicate code groups")
                print(f"   â€¢ Potential lines saved: {lines_saved}")

            elif analysis_type == "environment":
                critical = data.get("critical_hardcoded_values", 0)
                total = data.get("total_hardcoded_values", 0)
                print(f"   â€¢ Found {total} hardcoded values")
                print(f"   â€¢ Critical values: {critical}")

            elif analysis_type == "security":
                vulns = data.get("total_vulnerabilities", 0)
                critical_vulns = data.get("critical_vulnerabilities", 0)
                print(f"   â€¢ Found {vulns} potential vulnerabilities")
                print(f"   â€¢ Critical vulnerabilities: {critical_vulns}")

            elif analysis_type == "performance":
                total_issues = data.get("total_performance_issues", 0)
                critical_issues = data.get("critical_issues", 0)
                print(f"   â€¢ Found {total_issues} performance issues")
                print(f"   â€¢ Critical issues: {critical_issues}")

            elif analysis_type == "api_consistency":
                endpoints = data.get("total_endpoints", 0)
                inconsistencies = data.get("inconsistencies_found", 0)
                print(f"   â€¢ Analyzed {endpoints} API endpoints")
                print(f"   â€¢ Found {inconsistencies} consistency issues")

            elif analysis_type == "testing_coverage":
                total_funcs = data.get("total_functions", 0)
                coverage = data.get("test_coverage_percentage", 0)
                print(f"   â€¢ Analyzed {total_funcs} functions")
                print(f"   â€¢ Test coverage: {coverage}%")

            elif analysis_type == "architecture":
                components = data.get("total_components", 0)
                arch_issues = data.get("architectural_issues", 0)
                print(f"   â€¢ Analyzed {components} architectural components")
                print(f"   â€¢ Found {arch_issues} architectural issues")

    # Save comprehensive report
    report_path = Path("comprehensive_quality_report.json")
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2, default=str)

    # Generate summary report
    summary_path = Path("quality_summary.txt")
    with open(summary_path, "w") as f:
        f.write(summary)

    print(f"\n=== Reports Generated ===")
    print(f"ğŸ“‹ Comprehensive report: {report_path}")
    print(f"ğŸ“„ Executive summary: {summary_path}")

    return report


def get_score_status(score: float) -> str:
    """Get human-readable status for score"""
    if score >= 90:
        return "EXCELLENT"
    elif score >= 80:
        return "GOOD"
    elif score >= 70:
        return "FAIR"
    elif score >= 60:
        return "NEEDS IMPROVEMENT"
    else:
        return "CRITICAL"


def get_status_emoji(score: float) -> str:
    """Get status emoji based on score"""
    if score >= 90:
        return "ğŸŸ¢"
    elif score >= 80:
        return "ğŸŸ¡"
    elif score >= 70:
        return "ğŸŸ "
    else:
        return "ğŸ”´"


async def generate_action_plan(report):
    """Generate specific action plan based on results"""

    print("\n=== ğŸ“‹ Recommended Action Plan ===")

    metrics = report["quality_metrics"]
    issues = report["issue_summary"]

    # Phase 1: Critical Issues (Week 1)
    critical_count = issues["critical_issues"]
    if critical_count > 0:
        print(f"\nğŸš¨ **Phase 1: Critical Issues (IMMEDIATE - Week 1)**")
        print(f"   Address {critical_count} critical issues:")

        critical_issues = [
            i for i in report["prioritized_issues"] if i["severity"] == "critical"
        ]
        for issue in critical_issues[:5]:  # Top 5 critical
            print(f"   â€¢ {issue['title']}")
            print(f"     Action: {issue['fix_suggestion']}")

    # Phase 2: High Priority (Weeks 2-3)
    high_count = issues["high_priority_issues"]
    if high_count > 0:
        print(f"\nâš ï¸  **Phase 2: High Priority (Weeks 2-3)**")
        print(f"   Address {high_count} high priority issues:")

        if metrics["security_score"] < 80:
            print("   â€¢ Complete security vulnerability audit")
        if metrics["performance_score"] < 70:
            print("   â€¢ Fix performance bottlenecks and memory leaks")
        if metrics["test_coverage_score"] < 70:
            print("   â€¢ Increase test coverage to 80%+")

    # Phase 3: Quality Improvements (Month 2)
    print(f"\nğŸ”§ **Phase 3: Quality Improvements (Month 2)**")
    if metrics["architecture_score"] < 80:
        print("   â€¢ Refactor architectural issues")
    if metrics["code_duplication_score"] < 80:
        print("   â€¢ Eliminate code duplication")
    if metrics["api_consistency_score"] < 80:
        print("   â€¢ Standardize API patterns")

    # Phase 4: Maintenance & Monitoring (Ongoing)
    print(f"\nğŸ“ˆ **Phase 4: Continuous Improvement (Ongoing)**")
    print("   â€¢ Set up automated quality monitoring")
    print("   â€¢ Implement pre-commit quality checks")
    print("   â€¢ Regular quality reviews (weekly)")
    print("   â€¢ Update team coding standards")

    # Estimated timeline
    debt = report["technical_debt"]
    total_days = debt["estimated_total_effort_days"]
    critical_hours = debt["estimated_critical_effort_hours"]

    print(f"\nâ° **Estimated Timeline:**")
    print(f"   â€¢ Critical fixes: {critical_hours} hours (1-2 weeks)")
    print(f"   â€¢ Total remediation: {total_days} days ({total_days/5:.1f} weeks)")
    print(f"   â€¢ Team of 2-3 developers recommended")


async def main():
    """Run comprehensive code quality analysis"""

    # Run analysis
    report = await run_comprehensive_quality_analysis()

    # Generate action plan
    await generate_action_plan(report)

    print("\n=== ğŸ¯ Analysis Complete ===")
    print("Next Steps:")
    print("1. Review comprehensive_quality_report.json for detailed findings")
    print("2. Start with critical security and performance issues")
    print("3. Follow the recommended action plan phases")
    print("4. Set up automated quality monitoring")
    print("5. Schedule regular quality reviews")


if __name__ == "__main__":
    asyncio.run(main())
