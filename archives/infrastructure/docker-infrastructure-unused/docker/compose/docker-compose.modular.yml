# AutoBot Modular Docker Compose
# Uses standardized base images and eliminates duplicate patterns
# Implements Redis database separation and centralized data management

version: '3.8'

# Shared configurations (eliminates duplicate patterns across services)
x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

x-restart-policy: &default-restart
  restart: unless-stopped

x-agent-base: &agent-base
  build:
    context: .
    dockerfile: docker/base/Dockerfile.python-agent
    args:
      USER_ID: ${USER_ID:-1000}
      GROUP_ID: ${GROUP_ID:-1000}
  restart: unless-stopped
  networks:
    - autobot
  logging: *default-logging
  depends_on:
    autobot-redis:
      condition: service_healthy

services:
  # Core Infrastructure Services

  # Redis with database separation
  autobot-redis:
    image: redis:7.2-alpine
    container_name: autobot-redis
    <<: *default-restart
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --save 900 1 --save 300 10 --save 60 10000
      --maxmemory 2gb
      --maxmemory-policy allkeys-lru
      --databases 16
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - autobot_redis_data:/data
      - ${VOLUMES_DIR:-./docker/volumes}/config/redis-databases.yaml:/app/config/redis-databases.yaml:ro
    environment:
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://autobot-redis:6379
    networks:
      - autobot
    logging: *default-logging
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 15s
      timeout: 3s
      retries: 5
      start_period: 10s
    networks:
      autobot:
        ipv4_address: ${AUTOBOT_REDIS_HOST:-172.16.168.23}
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Ollama LLM Service
  autobot-ollama:
    image: ollama/ollama:latest
    container_name: autobot-ollama
    <<: *default-restart
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - autobot_ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=http://localhost:*,http://127.0.0.1:*,http://autobot-backend:*,http://${DOCKER_SUBNET:-172.16.168.0/24}
    networks:
      autobot:
        ipv4_address: ${AUTOBOT_BACKEND_HOST:-172.16.168.20}
    logging: *default-logging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'

  # Application Services

  # Backend API (uses main Redis database)
  autobot-backend:
    <<: *agent-base
    container_name: autobot-backend
    ports:
      - "${BACKEND_PORT:-8001}:8001"
    environment:
      - USER_ID=${USER_ID:-1000}
      - GROUP_ID=${GROUP_ID:-1000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - REDIS_HOST=${AUTOBOT_REDIS_HOST:-172.16.168.23}
      - REDIS_PORT=6379
      - REDIS_URL=redis://${AUTOBOT_REDIS_HOST:-172.16.168.23}:6379
      - SERVICE_TYPE=backend
      - HEALTH_CHECK_PORT=8001
      - REDIS_DATABASE=main
      - OLLAMA_HOST=http://${AUTOBOT_BACKEND_HOST:-172.16.168.20}:${AUTOBOT_OLLAMA_PORT:-11434}
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/prompts:/app/prompts:ro
      - ${VOLUMES_DIR:-./docker/volumes}/knowledge_base:/app/knowledge_base:ro
      - ${VOLUMES_DIR:-./docker/volumes}/config:/app/config:ro
      - ${VOLUMES_DIR:-./docker/volumes}/uploads:/app/uploads
      - autobot_backend_data:/app/data
      - autobot_backend_logs:/app/logs
    depends_on:
      autobot-redis:
        condition: service_healthy
      autobot-ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/system/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      autobot:
        ipv4_address: ${AUTOBOT_BACKEND_HOST:-172.16.168.20}
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
    command: ["uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "8001"]

  # AI Agents (each using specific Redis databases)

  # Chat Agent (lightweight, uses agents database)
  autobot-chat-agent:
    <<: *agent-base
    container_name: autobot-chat-agent
    build:
      context: .
      dockerfile: docker/agents/Dockerfile.chat-agent
      args:
        USER_ID: ${USER_ID:-1000}
        GROUP_ID: ${GROUP_ID:-1000}
    ports:
      - "${CHAT_AGENT_PORT:-8002}:8000"
    environment:
      - USER_ID=${USER_ID:-1000}
      - GROUP_ID=${GROUP_ID:-1000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://autobot-redis:6379
      - AGENT_TYPE=chat
      - HEALTH_CHECK_PORT=8000
      - REDIS_DATABASE=agents
      - DEFAULT_MODEL_NAME=${CHAT_MODEL:-llama3.2:1b}
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/prompts:/app/prompts:ro
      - ${VOLUMES_DIR:-./docker/volumes}/knowledge_base:/app/knowledge_base:ro
      - ${VOLUMES_DIR:-./docker/volumes}/config:/app/config:ro
      - autobot_chat_data:/app/data
      - autobot_chat_logs:/app/logs
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
    command: ["python", "src/agents/chat_agent_server.py"]

  # RAG Agent (uses knowledge database)
  autobot-rag-agent:
    <<: *agent-base
    container_name: autobot-rag-agent
    build:
      context: .
      dockerfile: docker/agents/Dockerfile.rag-agent
      args:
        USER_ID: ${USER_ID:-1000}
        GROUP_ID: ${GROUP_ID:-1000}
    ports:
      - "${RAG_AGENT_PORT:-8003}:8000"
    environment:
      - USER_ID=${USER_ID:-1000}
      - GROUP_ID=${GROUP_ID:-1000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://autobot-redis:6379
      - AGENT_TYPE=rag
      - HEALTH_CHECK_PORT=8000
      - REDIS_DATABASE=knowledge
      - DEFAULT_MODEL_NAME=${RAG_MODEL:-dolphin-llama3:8b}
      - VECTOR_DB_TYPE=chroma
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/prompts:/app/prompts:ro
      - ${VOLUMES_DIR:-./docker/volumes}/knowledge_base:/app/knowledge_base:ro
      - ${VOLUMES_DIR:-./docker/volumes}/config:/app/config:ro
      - autobot_rag_data:/app/data
      - autobot_rag_logs:/app/logs
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.5'
    command: ["python", "src/agents/rag_agent_server.py"]

  # NPU Code Search Agent (uses vectors database)
  autobot-npu-agent:
    <<: *agent-base
    container_name: autobot-npu-agent
    build:
      context: .
      dockerfile: docker/agents/Dockerfile.npu-agent
      args:
        USER_ID: ${USER_ID:-1000}
        GROUP_ID: ${GROUP_ID:-1000}
    ports:
      - "${NPU_AGENT_PORT:-8004}:8000"
    environment:
      - USER_ID=${USER_ID:-1000}
      - GROUP_ID=${GROUP_ID:-1000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://autobot-redis:6379
      - AGENT_TYPE=npu_code_search
      - HEALTH_CHECK_PORT=8000
      - REDIS_DATABASE=vectors
      - OPENVINO_DEVICE=AUTO
      - NPU_ACCELERATION_ENABLED=true
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/prompts:/app/prompts:ro
      - ${VOLUMES_DIR:-./docker/volumes}/knowledge_base:/app/knowledge_base:ro
      - ${VOLUMES_DIR:-./docker/volumes}/config:/app/config:ro
      - autobot_npu_data:/app/data
      - autobot_npu_logs:/app/logs
      - /dev:/dev:ro
      - /lib/firmware:/lib/firmware:ro
    privileged: true
    deploy:
      resources:
        limits:
          memory: 3G
          cpus: '2.0'
    command: ["python", "src/agents/npu_code_search_agent_server.py"]

  # Knowledge Agent (uses knowledge database)
  autobot-knowledge-agent:
    <<: *agent-base
    container_name: autobot-knowledge-agent
    build:
      context: .
      dockerfile: docker/agents/Dockerfile.knowledge-agent
      args:
        USER_ID: ${USER_ID:-1000}
        GROUP_ID: ${GROUP_ID:-1000}
    ports:
      - "${KNOWLEDGE_AGENT_PORT:-8005}:8000"
    environment:
      - USER_ID=${USER_ID:-1000}
      - GROUP_ID=${GROUP_ID:-1000}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - REDIS_HOST=autobot-redis
      - REDIS_PORT=6379
      - REDIS_URL=redis://autobot-redis:6379
      - AGENT_TYPE=knowledge
      - HEALTH_CHECK_PORT=8000
      - REDIS_DATABASE=knowledge
      - KNOWLEDGE_BASE_INDEX_ON_STARTUP=true
      - LOAD_KNOWLEDGE_BASE=true
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/prompts:/app/prompts:ro
      - ${VOLUMES_DIR:-./docker/volumes}/knowledge_base:/app/knowledge_base:ro
      - ${VOLUMES_DIR:-./docker/volumes}/config:/app/config:ro
      - autobot_knowledge_data:/app/data
      - autobot_knowledge_logs:/app/logs
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: '1.0'
    command: ["python", "src/agents/knowledge_agent_server.py"]

  # Frontend and Monitoring

  # Frontend (static files served by nginx)
  autobot-frontend:
    image: nginx:alpine
    container_name: autobot-frontend
    <<: *default-restart
    ports:
      - "${HTTP_PORT:-80}:80"
      - "${HTTPS_PORT:-443}:443"
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ${VOLUMES_DIR:-./docker/volumes}/nginx/conf.d:/etc/nginx/conf.d:ro
      - ${VOLUMES_DIR:-./docker/volumes}/static:/usr/share/nginx/html:ro
    networks:
      - autobot
    depends_on:
      autobot-backend:
        condition: service_healthy
    logging: *default-logging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

  # Prometheus (uses metrics database)
  autobot-prometheus:
    image: prom/prometheus:latest
    container_name: autobot-prometheus
    <<: *default-restart
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=15d'
      - '--web.enable-lifecycle'
    volumes:
      - ${VOLUMES_DIR:-./docker/volumes}/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - autobot_prometheus_data:/prometheus
    networks:
      - autobot
    logging: *default-logging
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
    profiles:
      - monitoring

# Centralized volumes (eliminates duplicate volume definitions)
volumes:
  # Infrastructure data
  autobot_redis_data:
    name: autobot_redis_data
  autobot_ollama_data:
    name: autobot_ollama_data
  autobot_prometheus_data:
    name: autobot_prometheus_data

  # Application data
  autobot_backend_data:
    name: autobot_backend_data
  autobot_backend_logs:
    name: autobot_backend_logs

  # Agent data (separated by agent type)
  autobot_chat_data:
    name: autobot_chat_data
  autobot_chat_logs:
    name: autobot_chat_logs
  autobot_rag_data:
    name: autobot_rag_data
  autobot_rag_logs:
    name: autobot_rag_logs
  autobot_npu_data:
    name: autobot_npu_data
  autobot_npu_logs:
    name: autobot_npu_logs
  autobot_knowledge_data:
    name: autobot_knowledge_data
  autobot_knowledge_logs:
    name: autobot_knowledge_logs

# Centralized network with real IP assignments
networks:
  autobot:
    name: autobot-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: ${DOCKER_SUBNET:-172.16.168.0/24}
          gateway: ${DOCKER_GATEWAY:-172.16.168.1}
