# AutoBot Docker Desktop Compose Configuration
# Optimized for Docker Desktop with 192.168.65.0/24 network

version: '3.8'

services:
  # Redis Cache and Message Broker
  redis:
    image: redis:7-alpine
    container_name: autobot-redis
    restart: unless-stopped
    ports:
      - "${AUTOBOT_REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    networks:
      autobot-network:
        ipv4_address: ${AUTOBOT_REDIS_IP:-192.168.65.10}
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  # Ollama LLM Service
  ollama:
    image: ollama/ollama:latest
    container_name: autobot-ollama
    restart: unless-stopped
    ports:
      - "${AUTOBOT_OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=http://localhost:*,http://127.0.0.1:*,http://192.168.65.0/24
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      autobot-network:
        ipv4_address: ${AUTOBOT_OLLAMA_IP:-192.168.65.20}
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'

  # AutoBot Backend Application
  autobot-backend:
    build:
      context: ../..
      dockerfile: docker/Dockerfile.production
      target: production
    container_name: autobot-backend
    restart: unless-stopped
    ports:
      - "${AUTOBOT_BACKEND_PORT:-8001}:8001"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config:/app/config
    environment:
      - AUTOBOT_ENVIRONMENT=docker-desktop
      - AUTOBOT_REDIS_HOST=${AUTOBOT_REDIS_IP:-192.168.65.10}
      - AUTOBOT_REDIS_PORT=${AUTOBOT_REDIS_PORT:-6379}
      - AUTOBOT_OLLAMA_HOST=http://${AUTOBOT_OLLAMA_IP:-192.168.65.20}:11434
      - AUTOBOT_LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/system/health"]
      interval: 20s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      autobot-network:
        ipv4_address: ${AUTOBOT_BACKEND_IP:-192.168.65.30}
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.5'

  # Frontend Reverse Proxy (Nginx)
  autobot-frontend:
    image: nginx:alpine
    container_name: autobot-frontend
    restart: unless-stopped
    ports:
      - "${AUTOBOT_FRONTEND_PORT:-5173}:80"
    volumes:
      - ./static:/usr/share/nginx/html
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - autobot-backend
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      autobot-network:
        ipv4_address: ${AUTOBOT_FRONTEND_IP:-192.168.65.40}
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

volumes:
  redis_data:
    driver: local
  ollama_data:
    driver: local

# Docker Desktop Network Configuration
networks:
  autobot-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: ${AUTOBOT_DOCKER_SUBNET:-192.168.65.0/24}
          gateway: ${AUTOBOT_DOCKER_GATEWAY:-192.168.65.1}