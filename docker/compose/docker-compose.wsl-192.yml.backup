# Docker Compose for WSL with 192.168.65.x Static IPs
# Uses Docker Desktop's internal subnet with static IP assignments
# Provides the performance benefits of direct IP communication

name: autobot

networks:
  autobot-192-network:
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.65.0/24
          gateway: 192.168.65.1

services:
  # Redis Stack with static IP
  autobot-redis:
    image: redis/redis-stack:7.4.0-v1
    container_name: autobot-redis
    restart: unless-stopped
    networks:
      autobot-192-network:
        ipv4_address: 192.168.65.10
    ports:
      - "127.0.0.1:6379:6379"    # WSL access via localhost
      - "127.0.0.1:8002:8002"    # Redis Insight via localhost
    volumes:
      - autobot_redis_data:/data
    environment:
      - REDIS_ARGS=--appendonly yes --save 60 1
      - REDISINSIGHT_PORT=8002
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "autobot.service=redis"
      - "autobot.ip=192.168.65.10"

  # AI Stack with static IP
  autobot-ai-stack:
    build:
      context: .
      dockerfile: docker/ai-stack/Dockerfile
    container_name: autobot-ai-stack
    restart: unless-stopped
    networks:
      autobot-192-network:
        ipv4_address: 192.168.65.20
    ports:
      - "127.0.0.1:8080:8080"    # WSL access via localhost
    depends_on:
      autobot-redis:
        condition: service_healthy
    volumes:
      # Centralized data volumes
      - ../volumes/prompts:/app/prompts:ro
      - ../volumes/knowledge_base:/app/knowledge_base:ro
      - ../volumes/models:/app/models
      - ../volumes/config:/app/config:ro
      # Container-specific volumes
      - autobot_ai_data:/app/data
      - autobot_ai_logs:/app/logs
      - ../../src:/app/src:ro
    environment:
      - AI_SERVER_HOST=0.0.0.0
      - AI_SERVER_PORT=8080
      - AI_SERVER_WORKERS=1
      - REDIS_HOST=192.168.65.10      # Direct IP connection to Redis
      - REDIS_PORT=6379
      - OLLAMA_HOST=192.168.65.30:11434
      - CHROMA_DB_PATH=/app/data/chroma_db
      - DISABLE_EXTERNAL_APIS=true
      - PYTHONPATH=/app:/app/src
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "autobot.service=ai-stack"
      - "autobot.ip=192.168.65.20"

  # NPU Worker with static IP
  autobot-npu-worker:
    build:
      context: ../..
      dockerfile: docker/npu-worker/Dockerfile.npu-worker-simple-worker
    container_name: autobot-npu-worker
    restart: unless-stopped
    networks:
      autobot-192-network:
        ipv4_address: 192.168.65.30
    ports:
      - "127.0.0.1:8081:8081"    # WSL access via localhost
    depends_on:
      autobot-redis:
        condition: service_healthy
    volumes:
      - ../volumes/prompts:/app/prompts:ro
      - ../volumes/knowledge_base:/app/knowledge_base:ro
      - ../volumes/models:/app/models
      - ../volumes/config:/app/config:ro
      - autobot_npu_logs:/app/logs
      - ../../src:/app/src:ro
      # Hardware access for NPU
      - /dev:/dev:ro
      - /lib/firmware:/lib/firmware:ro
      - /usr/local/lib:/usr/local/lib:ro
    environment:
      - NPU_WORKER_HOST=0.0.0.0
      - NPU_WORKER_PORT=8081
      - NPU_WORKER_WORKERS=1
      - REDIS_HOST=192.168.65.10      # Direct IP connection to Redis
      - REDIS_PORT=6379
      - NPU_LOG_LEVEL=INFO
      - OPENVINO_DEVICE=AUTO
      - OV_LOG_LEVEL=ERROR
      - PYTHONPATH=/app:/app/src
      - LD_LIBRARY_PATH=/usr/local/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib/python3.10
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    privileged: true
    # GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
    labels:
      - "autobot.service=npu-worker"
      - "autobot.ip=192.168.65.30"

  # Seq centralized logging with static IP
  autobot-seq:
    image: datalust/seq:latest
    container_name: autobot-seq
    restart: unless-stopped
    networks:
      autobot-192-network:
        ipv4_address: 192.168.65.40
    ports:
      - "127.0.0.1:5341:80"      # WSL access via localhost
    volumes:
      - autobot_seq_data:/data
    environment:
      - ACCEPT_EULA=Y
      - SEQ_FIRSTRUN_ADMINUSERNAME=admin
      - SEQ_FIRSTRUN_ADMINPASSWORD=autobot123
    healthcheck:
      test: ["CMD", "curl", "-f", "http://0.0.0.0:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    labels:
      - "autobot.service=seq"
      - "autobot.logging=centralized"
      - "autobot.ip=192.168.65.40"

  # Ollama (if needed) with static IP
  autobot-ollama:
    image: ollama/ollama:latest
    container_name: autobot-ollama
    restart: unless-stopped
    networks:
      autobot-192-network:
        ipv4_address: 192.168.65.50
    ports:
      - "127.0.0.1:11434:11434"  # WSL access via localhost
    volumes:
      - autobot_ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    labels:
      - "autobot.service=ollama"
      - "autobot.ip=192.168.65.50"
    profiles:
      - ollama  # Only start when ollama profile is specified

volumes:
  autobot_redis_data:
    name: autobot_redis_data
  autobot_ai_data:
    name: autobot_ai_data
  autobot_ai_logs:
    name: autobot_ai_logs
  autobot_npu_logs:
    name: autobot_npu_logs
  autobot_seq_data:
    name: autobot_seq_data
  autobot_ollama_data:
    name: autobot_ollama_data