# AutoBot Research Agent
# Extends standardized Python agent base image
# Optimized for web research and analysis

# Use standardized Python agent base
FROM python-agent-base:latest AS research-agent

# Agent-specific metadata
LABEL maintainer="AutoBot Team"
LABEL description="AutoBot Research Agent - Web research and analysis"
LABEL agent.type="research"
LABEL agent.capabilities="web_search,data_analysis,research_synthesis,fact_checking"

# Research agent specific configuration
ENV AGENT_TYPE=research \
    AGENT_NAME="AutoBot Research Agent" \
    AGENT_DESCRIPTION="Web research and analysis agent" \
    DEFAULT_MODEL_NAME=dolphin-llama3:8b \
    WEB_SEARCH_ENABLED=true \
    MAX_SEARCH_RESULTS=10 \
    RESEARCH_TIMEOUT=120 \
    FACT_CHECK_ENABLED=true \
    CITATION_FORMAT=apa

# Research agent specific dependencies
RUN pip install --no-cache-dir \
    beautifulsoup4==4.12.2 \
    requests==2.31.0 \
    selenium==4.15.2 \
    newspaper3k==0.2.8 \
    googlesearch-python==1.2.3 \
    wikipedia==1.4.0 \
    scholarly==1.7.11 \
    nltk==3.8.1 \
    spacy==3.7.2

# Download NLTK data and spaCy model
RUN python -m nltk.downloader punkt stopwords wordnet && \
    python -m spacy download en_core_web_sm

# Create research cache directory
RUN mkdir -p /app/data/research_cache /app/data/citations && \
    chown -R ${USER_ID}:${GROUP_ID} /app/data/research_cache /app/data/citations

# Agent-specific health check
ENV HEALTH_CHECK_PORT=8000
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:${HEALTH_CHECK_PORT}/health/research || exit 1

# Research agent startup command
CMD ["python", "src/agents/research_agent_server.py"]
