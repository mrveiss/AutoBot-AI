{
  "backend": {
    "api_endpoint": "http://localhost:8001",
    "server_host": "0.0.0.0",
    "server_port": 8001,
    "cors_origins": [
      "http://localhost:5173",
      "http://localhost:8080",
      "http://127.0.0.1:5173",
      "http://127.0.0.1:8080"
    ],
    "timeout": 60,
    "streaming": true,
    "max_retries": 3,
    "use_phi2": true,
    "ollama_endpoint": "http://localhost:11434/api/generate",
    "ollama_model": "phi:2.7b"
  },
  "llm_config": {
    "default_llm": "ollama",
    "task_llm": "ollama",
    "orchestrator_llm": "phi:2.7b",
    "orchestrator_llm_settings": {
      "temperature": 0.7,
      "structured_output": true
    },
    "task_llm_settings": {
      "temperature": 0.7,
      "structured_output": false
    },
    "ollama": {
      "host": "http://localhost:11434",
      "port": 11434,
      "model": "phi:2.7b",
      "base_url": "http://localhost:11434",
      "models": {
        "phi:2.7b": "phi:2.7b",
        "nomic-embed-text": "nomic-embed-text"
      }
    },
    "openai": {
      "api_key": "",
      "base_url": "",
      "model": "gpt-3.5-turbo"
    },
    "huggingface": {
      "api_key": "",
      "model": "microsoft/DialoGPT-medium"
    },
    "models": {
      "chat": {
        "provider": "ollama",
        "model": "phi:2.7b",
        "endpoint": "http://localhost:11434"
      },
      "embedding": {
        "provider": "ollama",
        "model": "nomic-embed-text",
        "endpoint": "http://localhost:11434"
      }
    }
  },
  "hardware_acceleration": {
    "priority": [
      "openvino_npu",
      "openvino",
      "cuda",
      "onnxruntime",
      "cpu"
    ]
  },
  "orchestrator": {
    "use_langchain": true,
    "simple_command_threshold": 10,
    "max_command_length": 500
  },
  "task_transport": {
    "type": "redis",
    "redis": {
      "host": "localhost",
      "port": 6379,
      "db": 0
    }
  },
  "memory": {
    "redis": {
      "enabled": true,
      "host": "localhost",
      "port": 6379,
      "db": 1
    }
  },
  "data": {
    "chat_history_file": "data/chat_history.json",
    "chat_data_dir": "data/chats",
    "knowledge_base_db": "data/knowledge_base.db",
    "reliability_stats_file": "data/reliability_stats.json",
    "audit_log_file": "data/audit.log"
  },
  "diagnostics": {
    "enabled": true,
    "reliability_stats_file": "data/reliability_stats.json",
    "use_llm_for_analysis": true,
    "use_web_search_for_analysis": false,
    "auto_apply_fixes": false
  },
  "llama_index": {
    "vector_store": {
      "type": "redis",
      "redis": {
        "host": "localhost",
        "port": 6379,
        "index_name": "autobot_index"
      }
    },
    "embedding": {
      "provider": "ollama",
      "model": "nomic-embed-text",
      "endpoint": "http://localhost:11434"
    }
  },
  "security": {
    "user_permissions": {
      "user": {
        "allow_goal_submission": true,
        "allow_shell_execute": true,
        "allow_chat_control": true,
        "allow_voice_listen": true,
        "allow_voice_speak": true,
        "allow_agent_control": true,
        "allow_command_approval": true
      }
    }
  },
  "logging": {
    "level": "INFO",
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  },
  "ui": {
    "theme": "light",
    "font_size": "medium"
  },
  "chat": {
    "max_messages": 100,
    "auto_scroll": true
  },
  "message_display": {
    "show_thoughts": true,
    "show_planning": true,
    "show_debug": false,
    "show_utility": false,
    "show_json": false
  },
  "settings": {
    "message_display": {
      "show_thoughts": true,
      "show_json": false,
      "show_utility": false,
      "show_planning": true,
      "show_debug": false
    },
    "chat": {
      "auto_scroll": true,
      "max_messages": 100,
      "message_retention_days": 30
    },
    "backend": {
      "api_endpoint": "http://localhost:8001",
      "server_host": "localhost",
      "server_port": 8001,
      "chat_data_dir": "",
      "chat_history_file": "",
      "knowledge_base_db": "",
      "reliability_stats_file": "",
      "audit_log_file": "",
      "cors_origins": [
        "http://localhost:5173",
        "http://localhost:8080",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:8080"
      ],
      "timeout": 60,
      "max_retries": 3,
      "streaming": true,
      "llm": {
        "provider_type": "local",
        "local": {
          "provider": "ollama",
          "providers": {
            "ollama": {
              "endpoint": "",
              "models": [],
              "selected_model": ""
            },
            "lmstudio": {
              "endpoint": "",
              "models": [],
              "selected_model": ""
            }
          }
        },
        "cloud": {
          "provider": "openai",
          "providers": {
            "openai": {
              "api_key": "",
              "endpoint": "",
              "models": [],
              "selected_model": ""
            },
            "anthropic": {
              "api_key": "",
              "endpoint": "",
              "models": [],
              "selected_model": ""
            }
          }
        }
      },
      "use_phi2": true,
      "ollama_endpoint": "http://localhost:11434/api/generate",
      "ollama_model": "phi:2.7b"
    },
    "ui": {
      "theme": "light",
      "font_size": "medium",
      "language": "en",
      "animations": true,
      "developer_mode": false
    },
    "security": {
      "enable_encryption": false,
      "session_timeout_minutes": 30,
      "user_permissions": {
        "user": {
          "allow_goal_submission": true,
          "allow_shell_execute": true,
          "allow_chat_control": true,
          "allow_voice_listen": true,
          "allow_voice_speak": true,
          "allow_agent_control": true,
          "allow_command_approval": true
        }
      }
    },
    "logging": {
      "log_level": "info",
      "log_to_file": false,
      "log_file_path": "",
      "level": "INFO",
      "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    },
    "knowledge_base": {
      "enabled": true,
      "update_frequency_days": 7
    },
    "voice_interface": {
      "enabled": false,
      "voice": "default",
      "speech_rate": 1
    },
    "memory": {
      "long_term": {
        "enabled": true,
        "retention_days": 30
      },
      "short_term": {
        "enabled": true,
        "duration_minutes": 30
      },
      "vector_storage": {
        "enabled": true,
        "update_frequency_days": 7
      },
      "chromadb": {
        "enabled": true,
        "path": "",
        "collection_name": ""
      },
      "redis": {
        "enabled": true,
        "host": "localhost",
        "port": 6379,
        "db": 1
      }
    },
    "prompts": {
      "list": [
        {
          "name": "task_system_prompt",
          "content": "You are a highly skilled problem-solver and code implementer. \nExecute the given task with precision and efficiency.\nAllways break down the task into a concise, actionable, numbered list of steps.\nEach step MUST be a direct instruction to use one of the available tools.\nYou MUST NOT include ANY conversational text, explanations, or hypothetical answers.\n"
        },
        {
          "name": "tool_interpreter_system_prompt",
          "content": "You are a tool interpreter. Your ONLY output MUST be a JSON object representing a tool call. You MUST NOT include ANY conversational text, explanations, or hypothetical answers. Respond SOLELY with the JSON object.\n\nThe JSON object MUST have the following structure:\n{\n    \"tool_type\": \"string\", // e.g., \"system_execute_command\", \"gui_type_text\", \"knowledge_base_search\"\n    \"parameters\": {\n        \"param1\": \"value1\",\n        \"param2\": \"value2\"\n    }\n}\n\nHere are the available tool types and their parameters:\n\n- GUI Automation:\n    - tool_type: \"gui_type_text\"\n      parameters: {\"text\": \"TEXT_TO_TYPE\"}\n    - tool_type: \"gui_click_element\"\n      parameters: {\"image_path\": \"PATH_TO_IMAGE\"}\n    - tool_type: \"gui_read_text_from_region\"\n      parameters: {\"x\": INT, \"y\": INT, \"width\": INT, \"height\": INT}\n    - tool_type: \"gui_bring_window_to_front\"\n      parameters: {\"app_title\": \"APP_WINDOW_TITLE\"}\n\n- System Integration:\n    - tool_type: \"system_query_info\"\n      parameters: {}\n    - tool_type: \"system_list_services\"\n      parameters: {}\n    - tool_type: \"system_manage_service\"\n      parameters: {\"service_name\": \"SERVICE_NAME\", \"action\": \"start|stop|restart\"}\n    - tool_type: \"system_execute_command\"\n      parameters: {\"command\": \"CLI_COMMAND\"}\n    - tool_type: \"system_get_process_info\"\n      parameters: {\"process_name\": \"PROCESS_NAME\"} OR {\"pid\": INT}\n    - tool_type: \"system_terminate_process\"\n      parameters: {\"pid\": INT}\n\n- Knowledge Base:\n    - tool_type: \"knowledge_base_add_file\"\n      parameters: {\"file_path\": \"FILE_PATH\", \"file_type\": \"FILE_TYPE\", \"metadata\": {JSON_METADATA}}\n    - tool_type: \"knowledge_base_search\"\n      parameters: {\"query\": \"SEARCH_QUERY\", \"n_results\": INT}\n    - tool_type: \"knowledge_base_store_fact\"\n      parameters: {\"content\": \"FACT_CONTENT\", \"metadata\": {JSON_METADATA}}\n    - tool_type: \"knowledge_base_get_fact\"\n      parameters: {\"fact_id\": INT} OR {\"query\": \"QUERY\"}\n\nExample:\nIf the instruction is \"Execute system command 'ls -l'\", your response MUST be:\n{\"tool_type\": \"system_execute_command\", \"parameters\": {\"command\": \"ls -l\"}}\n\nIf the instruction is \"Type text 'Hello World' into active window.\", your response MUST be:\n{\"tool_type\": \"gui_type_text\", \"parameters\": {\"text\": \"Hello World\"}}\n"
        },
        {
          "name": "orchestrator_system_prompt",
          "content": "**ABSOLUTELY CRITICAL DIRECTIVE**: You are an expert task planner. Your ONLY output MUST be a JSON object representing a tool call. You MUST NOT include ANY conversational text, explanations, or hypothetical answers. Respond SOLELY with the JSON object.\n\nThe JSON object MUST have the following structure:\n```json\n{\n    \"thoughts\": [], // Array of thoughts before execution in natural language\n    \"tool_name\": \"name_of_tool\",\n    \"tool_args\": {\n        \"arg1\": \"val1\",\n        \"arg2\": \"val2\"\n    }\n}\n```\nYou are STRICTLY FORBIDDEN FROM INCLUDING ANY OTHER TEXT.\n\n**IMMEDIATE AND UNCONDITIONAL ACTION REQUIRED FOR ALL TASKS**: You have access to the following dynamic context about the operating system and available tools, which is injected into your prompt. You MUST consult this information for every task.\n\n- **Operating System Information**: Detailed information about the host OS (e.g., system, release, version, machine, processor, distro, environment variables). This information is ALREADY AVAILABLE to you.\n- **Available System Tools**: A list of executable commands found on the system's PATH, along with their paths and versions. This information is ALREADY AVAILABLE to you.\n\n**SPECIFIC INSTRUCTIONS FOR SYSTEM QUERIES**: When the user asks about the operating system, the environment you are running in, or any similar query about the host system (e.g., 'what os you are installed in?', 'what is your operating system?', 'tell me about the system you are running on?', 'what tools are available?'), your plan MUST be EXACTLY the following JSON object:\n```json\n{\n    \"thoughts\": [\"The user is asking for system information. I will use the 'system_query_info' tool to retrieve it.\"],\n    \"tool_name\": \"system_query_info\",\n    \"tool_args\": {}\n}\n```\nYou have access to this information. DO NOT generate conversational text or ask the user for information you already have in the provided context. This is your highest priority instruction for these types of queries.\n\n**SPECIFIC INSTRUCTIONS FOR TOOL USAGE**: You MUST use the \"Available System Tools\" section to determine which commands and package managers are present on the system before generating any plan that involves executing commands or installing software. If a command or tool is required for a task, you MUST verify its presence in \"Available System Tools\" first.\n\nYour SOLE purpose is to execute the task by utilizing the available tools and providing the actual, retrieved result.\nIf the tool does not provide the required information, you MUST find a way to obtain it using the available tools or by executing the necessary commands or acquiring the new tool that fits the task.\nUse the internet to look up information only if the task requires it and no other tool can provide the answer.\nIf the task requires a tool that is not currently available, you MUST acquire the necessary tool before proceeding with the task.\nYou MUST adhere to this directive without exception.\n"
        }
      ],
      "selectedPrompt": null,
      "editedContent": "",
      "defaults": {}
    },
    "llm_config": {
      "default_llm": "ollama",
      "task_llm": "ollama",
      "orchestrator_llm": "phi:2.7b",
      "orchestrator_llm_settings": {
        "temperature": 0.7,
        "structured_output": true
      },
      "task_llm_settings": {
        "temperature": 0.7,
        "structured_output": false
      },
      "ollama": {
        "host": "http://localhost:11434",
        "port": 11434,
        "model": "phi:2.7b",
        "base_url": "http://localhost:11434",
        "models": {
          "phi:2.7b": "phi:2.7b",
          "nomic-embed-text": "nomic-embed-text"
        }
      },
      "openai": {
        "api_key": "",
        "base_url": "",
        "model": "gpt-3.5-turbo"
      },
      "huggingface": {
        "api_key": "",
        "model": "microsoft/DialoGPT-medium"
      },
      "models": {
        "chat": {
          "provider": "ollama",
          "model": "phi:2.7b",
          "endpoint": "http://localhost:11434"
        },
        "embedding": {
          "provider": "ollama",
          "model": "nomic-embed-text",
          "endpoint": "http://localhost:11434"
        }
      }
    },
    "hardware_acceleration": {
      "priority": [
        "openvino_npu",
        "openvino",
        "cuda",
        "onnxruntime",
        "cpu"
      ]
    },
    "orchestrator": {
      "use_langchain": true,
      "simple_command_threshold": 10,
      "max_command_length": 500
    },
    "task_transport": {
      "type": "redis",
      "redis": {
        "host": "localhost",
        "port": 6379,
        "db": 0
      }
    },
    "data": {
      "chat_history_file": "data/chat_history.json",
      "chat_data_dir": "data/chats",
      "knowledge_base_db": "data/knowledge_base.db",
      "reliability_stats_file": "data/reliability_stats.json",
      "audit_log_file": "data/audit.log"
    },
    "diagnostics": {
      "enabled": true,
      "reliability_stats_file": "data/reliability_stats.json",
      "use_llm_for_analysis": true,
      "use_web_search_for_analysis": false,
      "auto_apply_fixes": false
    },
    "llama_index": {
      "vector_store": {
        "type": "redis",
        "redis": {
          "host": "localhost",
          "port": 6379,
          "index_name": "autobot_index"
        }
      },
      "embedding": {
        "provider": "ollama",
        "model": "nomic-embed-text",
        "endpoint": "http://localhost:11434"
      }
    }
  }
}