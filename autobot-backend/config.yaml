hardware_acceleration:
  agent_device_assignments:
    analysis: gpu
    chat: gpu
    code: gpu
    knowledge_retrieval: gpu
    orchestrator: gpu
    planning: gpu
    rag: gpu
    research: gpu
    search: gpu
    system_commands: cpu
  gpu_optimization:
    device_id: 0
    enabled: true
    fp16_optimization: true
    memory_limit_mb: 6000
    parallel_requests: 2
  priority:
  - cuda
  - openvino
  - cpu
llm_config:
  default_provider: ollama
  active_provider: ollama
  fallback_chain:
    - ollama
    - openai
    - vllm
    - transformers
    - mock
  fallback_enabled: true
  ollama:
    context_length: 4096
    gpu_enabled: true
    gpu_layers: 999
    host: ${AUTOBOT_OLLAMA_URL:-http://127.0.0.3:11434}
    parallel_requests: 2
