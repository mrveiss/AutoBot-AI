# Critical Priority Task Breakdown
**Generated**: 2025-08-03 06:11:47
**Branch**: analysis-report-20250803
**Analysis Scope**: Full codebase
**Priority Level**: Critical

## Executive Summary
This document outlines the most critical issues discovered in the AutoBot codebase. These tasks must be addressed immediately to mitigate severe security risks and fix non-functional core components. Failure to do so leaves the application and its host environment vulnerable and unstable.

## Impact Assessment
- **Timeline Impact**: Immediate. These tasks should be the sole focus of the development team until completed. Estimated 3-5 days of intensive work.
- **Resource Requirements**: 1-2 Senior Backend Engineers with experience in security and asynchronous systems.
- **Business Value**: **Critical**. Resolving these issues is essential for product viability, user trust, and data security.
- **Risk Level**: **Critical**. Each of these tasks addresses a critical vulnerability or a complete failure of a core system.

---

## TASK: Secure File Management API
**Priority**: Critical
**Effort Estimate**: 1-2 days
**Impact**: Fixes a critical security vulnerability that allows any unauthenticated user to read, write, and delete files within the application's data sandbox.
**Dependencies**: A clear definition of user roles and their intended permissions.
**Risk Factors**: Modifying security-sensitive code could introduce new vulnerabilities if not done carefully. Lack of existing tests means verification must be done manually or with new, dedicated tests.

### Subtasks:
#### 1. Implement Role-Based Access Control (RBAC)
**Owner**: Backend Team / Security Lead
**Estimate**: 8 hours
**Prerequisites**: None.

**Steps**:
1.  **Integrate Security Layer**: In `backend/api/files.py`, modify the `check_file_permissions` function to call the `SecurityLayer.check_permission` method instead of returning `True`.
2.  **Define Permissions**: In `src/security_layer.py`, define specific permissions for file operations (e.g., `files.view`, `files.upload`, `files.delete`, `files.download`).
3.  **Enforce Checks**: Ensure that each endpoint in `backend/api/files.py` calls `check_file_permissions` with the appropriate required permission. For example, the `/delete` endpoint should require the `files.delete` permission.
4.  **Handle Authentication**: For now, a placeholder mechanism can be used to assign a role (e.g., based on a header), but this should be clearly marked for replacement by a proper authentication system.

**Success Criteria**:
- [ ] API requests to `/api/files/*` endpoints without proper (mocked) authorization fail with a 403 Forbidden status.
- [ ] API requests with sufficient authorization succeed.
- [ ] The `delete` endpoint is verifiably protected.

**Testing Requirements**:
- [ ] Add new integration tests that attempt to access each file API endpoint with and without valid permissions.
- [ ] Manually verify endpoints using an API client like Postman or curl.

---

## TASK: Mitigate Shell Injection Risk from LLM-Generated Commands
**Priority**: Critical
**Effort Estimate**: 1 day
**Impact**: Prevents potential arbitrary code execution on the host machine by validating and sanitizing commands generated by the LLM before they are executed.
**Dependencies**: None.
**Risk Factors**: An overly restrictive whitelist may break legitimate agent functionality. An incomplete blacklist could still allow malicious commands.

### Subtasks:
#### 1. Implement Command Whitelisting and Sanitization
**Owner**: Backend Team
**Estimate**: 6 hours
**Prerequisites**: None.

**Steps**:
1.  **Create Whitelist**: In a new configuration file or within `src/config.py`, define a strict whitelist of permissible commands and their expected argument patterns (e.g., using regex). Examples: `ls`, `ps aux`, `netstat -tuln`.
2.  **Implement Validator**: In `src/worker_node.py`, before the `asyncio.create_subprocess_shell` call within the `execute_shell_command` task, create a new function to validate the incoming `command` string against the whitelist.
3.  **Reject or Sanitize**: If a command does not match the whitelist, the task should immediately fail with a security error. Do not attempt to sanitize a failed command; reject it outright.
4.  **Refactor to `shell=False`**: For whitelisted commands where the argument structure is predictable (e.g., `ls -la`), refactor the call to use `shell=False` and pass the command and arguments as a list (e.g., `['ls', '-la']`). This is the most effective mitigation.

**Success Criteria**:
- [ ] An attempt to execute a non-whitelisted command (e.g., `rm -rf /`) is blocked and logged as a security event.
- [ ] An attempt to inject a command (e.g., `ls; whoami`) is blocked.
- [ ] Legitimate, whitelisted commands continue to execute successfully.

**Testing Requirements**:
- [ ] Write unit tests for the new validation function with examples of both malicious and benign commands.
- [ ] Manually test the `execute_goal` endpoint with prompts designed to trigger dangerous commands.

---

## TASK: Enable and Fix Core Orchestrator Functionality
**Priority**: Critical
**Effort Estimate**: 1 day
**Impact**: Restores the agent's core ability to handle asynchronous tasks and communicate with distributed workers via Redis, which is currently non-functional.
**Dependencies**: A running Redis instance for testing.
**Risk Factors**: Race conditions or deadlocks could be introduced if the asynchronous logic is not handled correctly.

### Subtasks:
#### 1. Activate and Implement Redis Listeners
**Owner**: Backend Team
**Estimate**: 5 hours
**Prerequisites**: None.

**Steps**:
1.  **Re-enable Listeners**: In `backend/app_factory.py`, uncomment the `asyncio.create_task` calls for `_listen_for_command_approvals` and `_listen_for_worker_capabilities` within the `_initialize_orchestrator` function.
2.  **Implement `_listen_for_worker_capabilities`**: The current implementation in `src/orchestrator.py` is a placeholder (`asyncio.sleep(1)`). Implement the full logic to subscribe to the `worker_capabilities` Redis channel and update the `self.worker_capabilities` dictionary.
3.  **Test Approval Workflow**: Thoroughly test the command approval workflow. This involves triggering a task that requires approval, publishing an "approved" message to the correct Redis channel, and verifying that the orchestrator receives it and continues the task.

**Success Criteria**:
- [ ] The orchestrator successfully receives and processes capability reports published by worker nodes on startup.
- [ ] The command approval workflow functions end-to-end via Redis pub/sub.
- [ ] The server logs show that the background tasks are running without errors.

**Testing Requirements**:
- [ ] Create a simple script that acts as a mock "worker" to publish capability and approval messages to Redis for testing purposes.
- [ ] Manually test an agent goal that requires command approval.
